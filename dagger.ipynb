{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import random\n",
    "\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "env_name = \"Skiing-v0\"\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render(x, step=0):\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.clf()\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"step: %d\" % step)\n",
    "    plt.imshow(x, cmap=plt.cm.gray)\n",
    "    plt.pause(0.001)   # pause for plots to update\n",
    "  \n",
    "def pre_processing(observe):\n",
    "    processed_observe = resize(observe[54:-52,8:152], (64, 64), mode='reflect', anti_aliasing=True)\n",
    "    return processed_observe\n",
    "  \n",
    "def batch(batch_size=32):\n",
    "  n_data = len(obss)\n",
    "  ids = np.random.choice(n_data, batch_size, replace=False)\n",
    "  b_o = obss[ids]\n",
    "  b_a = acts[ids]\n",
    "  return b_o, b_a\n",
    "\n",
    "def model(x, name='policy'):\n",
    "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "    x = tf.layers.conv2d(x, 16, 8, strides=4, activation=tf.nn.relu)\n",
    "    x = tf.layers.conv2d(x, 32, 4, strides=2, activation=tf.nn.relu)\n",
    "    x = tf.layers.conv2d(x, 64, 3, strides=1, activation=tf.nn.relu)\n",
    "    x = tf.layers.flatten(x)\n",
    "    x = tf.layers.dense(x, 512, activation=tf.nn.relu)\n",
    "    x = tf.layers.dense(x, 3)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Objects can be distinquished by RGB codes.\n",
    "# Player: [214, 92, 92]\n",
    "# Flags (blue): [66, 72, 200]\n",
    "# Flags (red): [184, 50, 50]\n",
    "\n",
    "def get_pos_player(observe):\n",
    "  ids = np.where(np.sum(observe == [214, 92, 92], -1) == 3)\n",
    "  return ids[0].mean(), ids[1].mean()\n",
    "\n",
    "def get_pos_flags(observe):\n",
    "  if np.any(np.sum(observe == [184, 50, 50], -1) == 3):\n",
    "    ids = np.where(np.sum(observe == [184, 50, 50], -1) == 3)\n",
    "    return ids[0].mean(), ids[1].mean()\n",
    "  else:\n",
    "    base = 0\n",
    "    ids = np.where(np.sum(observe[base:-60] == [66, 72, 200], -1) == 3)\n",
    "    return ids[0].mean() + base, ids[1].mean()\n",
    "\n",
    "def get_speed(observe, observe_old):\n",
    "  min_val = np.inf\n",
    "  min_idx = 0\n",
    "  for k in range(0, 7):\n",
    "    val = np.sum(np.abs(observe[54:-52,8:152] - observe_old[54+k:-52+k,8:152]))\n",
    "    if min_val > val:\n",
    "      min_idx = k\n",
    "      min_val = val\n",
    "  return min_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hparams & Data containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cont = 4\n",
    "obss = np.empty((0, 64, 64, 3*n_cont))\n",
    "acts = np.empty((0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 64, 64, 3*n_cont))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "y_onehot = tf.one_hot(y, 3)\n",
    "\n",
    "y_hat = model(x)\n",
    "p_hat = tf.nn.softmax(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_onehot, logits=y_hat))\n",
    "opt = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for episode in range(1000):\n",
    "  observe = env.reset()\n",
    "  step = 0\n",
    "  cnt = 0\n",
    "  done = False\n",
    "  r_a, c_a = get_pos_player(observe)\n",
    "  r_f, c_f = get_pos_flags(observe)\n",
    "  r_a_old, c_a_old = r_a, c_a\n",
    "  observe_old = observe\n",
    "  history = np.concatenate([pre_processing(observe)] * n_cont, -1)\n",
    "\n",
    "  outs_o = []\n",
    "  outs_a = []\n",
    "  while not done:\n",
    "    step += 1\n",
    "\n",
    "    # TEACHER\n",
    "    v_f = np.arctan2(r_f - r_a, c_f - c_a) # direction from player to target\n",
    "    spd = get_speed(observe, observe_old)\n",
    "    v_a = np.arctan2(spd, c_a - c_a_old) # speed vector of the player\n",
    "    r_a_old, c_a_old = r_a, c_a\n",
    "    observe_old = observe\n",
    "    if spd == 0 and (c_a - c_a_old) == 0:\n",
    "      # no movement\n",
    "      cnt += 1\n",
    "      act_t = np.random.choice(3, 1)[0]\n",
    "    else:\n",
    "      cnt = 0\n",
    "      if v_f - v_a < -0.1:\n",
    "        act_t = 1\n",
    "      elif v_f - v_a > 0.1:\n",
    "        act_t = 2\n",
    "      else:\n",
    "        act_t = 0\n",
    "\n",
    "    if cnt > 10:\n",
    "      print('no movement!')\n",
    "      break\n",
    "    \n",
    "    outs_o.append(history)\n",
    "    outs_a.append(act_t)\n",
    "    \n",
    "    p = sess.run(p_hat, feed_dict={x: [history]})[0]\n",
    "    act = np.random.choice(3, 1, p=p)[0]\n",
    "    observe, reward, done, info = env.step(act)\n",
    "    history = np.concatenate([pre_processing(observe), history[:,:,3:]], -1)\n",
    "    r_a, c_a = get_pos_player(observe)\n",
    "    r_f, c_f = get_pos_flags(observe)\n",
    "  \n",
    "  # append data & limit data size\n",
    "  obss = np.concatenate([obss, outs_o], 0)\n",
    "  acts = np.concatenate([acts, outs_a], 0)\n",
    "  if len(obss) > 5000:\n",
    "    obss = obss[-5000:]\n",
    "    acts = acts[-5000:]\n",
    "\n",
    "  for i in range(500):\n",
    "    d_x, d_y = batch()\n",
    "    ret = sess.run([opt, loss], feed_dict={x: d_x, y: d_y})\n",
    "    print('%5d %5d' % (episode, i), ret[1], end='\\r')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observe = env.reset()\n",
    "done = False\n",
    "history = np.concatenate([pre_processing(observe)] * n_cont, -1)\n",
    "\n",
    "tmp_obs = [observe]\n",
    "while not done:\n",
    "  p = sess.run(p_hat, feed_dict={x: [history]})[0]\n",
    "  act = np.random.choice(3, 1, p=p)[0]\n",
    "  observe, reward, done, info = env.step(act)\n",
    "  history = np.concatenate([pre_processing(observe), history[:,:,3:]], -1)\n",
    "  tmp_obs.append(observe)\n",
    "\n",
    "for i, o in enumerate(tmp_obs):\n",
    "  if i % 3 == 0:\n",
    "    render(o[:,:,:3][28:-52,8:152], i)\n",
    "render(o[:,:,:3][28:-52,8:152], i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
